#helper to speed up
get_rf_vars <- function(sample.df, model.vars,outcome.name,test.df){
#Get the top variables chosen by RF for different samples sizes
#helper functions
fit.rf <- function(df, model.vars,outcome.name,test.df){
#function that will fit a rf and return top 10 most important varibales
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name, colnames(df))
#get x and y dataframes
df.x <- df[,-y.idx]; df.y <- as.factor(df[,y.idx])
#fit rf
rfFuncs$summary <- twoClassSummary;
ctrl <- rfeControl(functions=rfFuncs, method = 'cv', repeats = 5,verbose = F,
allowParallel = T,saveDetails = T)
subsets <- seq(1,25,3)
rf <- rfe(x=df.x,y=df.y,data = df,sizes = subsets, metric = "ROC", rfeControl = ctrl)
#get top variables
in.model <- as.numeric(model.vars %in% rf$optVariables)
#get roc value
idx <- rf$results$Variables == rf$optsize
roc.val <- rf$results[idx,2]
spec.sens <- spec_for_sens(rf,test.df)
return(c(in.model,"RF",n, roc.val, spec.sens))
}
#fit row and get vars chosen
out.row <- as.data.frame(t(fit.rf(sample.df, model.vars,outcome.name,test.df)))
model.vars <- c(model.vars, "method", "N", "ROC", "spec_for_sens")
names(out.row) <- model.vars
return(out.row)
}
#fit in parallel and get the results
#make cluster
cl <- makeCluster(detectCores())
clusterEvalQ(cl, {library(caret)})
results <- parLapply(cl,sample.list, get_rf_vars,
model.vars = model.vars, outcome.name = outcome.name,
test.df=test.df)
stopCluster(cl)
#Fitting takes ~ 480seconds
return(results)
}
rf_result <- get_rf_results(sample.list,column.names,y.name,test.df)
rf_result
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(model, test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
sample.df <- sample.list[[1]]
df <- sample.df
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name, colnames(df))
outcome.name <- y.name
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name, colnames(df))
#get x and y dataframes
df.x <- df[,-y.idx]; df.y <- as.factor(df[,y.idx])
#fit stepwiseAIC regression to glm object
train.ctrl <- trainControl("cv", 5,summaryFunction = twoClassSummary,
classProbs = T, allowParallel = T,
savePredictions = T)
fit.aic <- train(x = df.x , y = df.y,
method = "glmStepAIC",family=binomial(),
trControl = train.ctrl ,metric = 'ROC', trace=F)
#get vars
top.vars <- variable.names(fit.aic$finalModel)
#score variable with 1 if it is in the model and 0 o.w
in.model <- as.numeric(model.vars %in% top.vars)
roc.val <- fit.aic$results$ROC
roc.val
top.vars
in.model
spec_for_sens(fit.aic$finalModel,test.df)
spec_for_sens(fit.aic,test.df)
#stepwise
get_stepwise_results <- function(sample.list, model.vars,outcome.name, test.df){
#Fits in parallel stepwiseAIC to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(model, test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
#helper to speed up
get_stepaic_vars <- function(sample.df, model.vars,outcome.name,test.df){
fit.stepwise <- function(df, model.vars,outcome.name,test.df){
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name, colnames(df))
#get x and y dataframes
df.x <- df[,-y.idx]; df.y <- as.factor(df[,y.idx])
#fit stepwiseAIC regression to glm object
train.ctrl <- trainControl("cv", 5,summaryFunction = twoClassSummary,
classProbs = T, allowParallel = T,
savePredictions = T)
fit.aic <- train(x = df.x , y = df.y,
method = "glmStepAIC",family=binomial(),
trControl = train.ctrl ,metric = 'ROC', trace=F)
#get vars
top.vars <- variable.names(fit.aic$finalModel)
#score variable with 1 if it is in the model and 0 o.w
in.model <- as.numeric(model.vars %in% top.vars)
roc.val <- fit.aic$results$ROC
spec.sens <- spec_for_sens(fit.aic,test.df)
return(c(in.model,"stepAIC",n, roc.val, spec.sens))
}
#fit row and get vars chosen
out.row <- as.data.frame(t(fit.stepwise(sample.df,model.vars,outcome.name,test.df)))
model.vars <-c(model.vars, "method", "N", "ROC", "spec_for_sens")
names(out.row) <- model.vars
return(out.row)
fit.stepwise(sample.df,model.vars)
}
#fit in parallel and get the results
cl <- makeCluster(detectCores())
clusterEvalQ(cl, library(caret))
results <- parLapply(cl, sample.list, get_stepaic_vars,
model.vars = model.vars, outcome.name = outcome.name,
test.df = test.df)
stopCluster(cl)
return(results)
}
test_aic <- get_stepwise_results(sample.list,column.names,y.name,test.df)
#stepwise
get_stepwise_results <- function(sample.list, model.vars,outcome.name, test.df){
#Fits in parallel stepwiseAIC to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(model, test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
#helper to speed up
get_stepaic_vars <- function(sample.df, model.vars,outcome.name,test.df){
fit.stepwise <- function(df, model.vars,outcome.name,test.df){
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name, colnames(df))
#get x and y dataframes
df.x <- df[,-y.idx]; df.y <- as.factor(df[,y.idx])
#fit stepwiseAIC regression to glm object
train.ctrl <- trainControl("cv", 5,summaryFunction = twoClassSummary,
classProbs = T, allowParallel = T,
savePredictions = T)
fit.aic <- train(x = df.x , y = df.y,
method = "glmStepAIC",family=binomial(),
trControl = train.ctrl ,metric = 'ROC', trace=F)
#get vars
top.vars <- variable.names(fit.aic$finalModel)
#score variable with 1 if it is in the model and 0 o.w
in.model <- as.numeric(model.vars %in% top.vars)
roc.val <- fit.aic$results$ROC
spec.sens <- spec_for_sens(fit.aic,test.df)
return(c(in.model,"stepAIC",n, roc.val, spec.sens))
}
#fit row and get vars chosen
out.row <- as.data.frame(t(fit.stepwise(sample.df,model.vars,outcome.name,test.df)))
model.vars <-c(model.vars, "method", "N", "ROC", "spec_for_sens")
names(out.row) <- model.vars
return(out.row)
}
#fit in parallel and get the results
cl <- makeCluster(detectCores())
clusterEvalQ(cl, library(caret))
results <- parLapply(cl, sample.list, get_stepaic_vars,
model.vars = model.vars, outcome.name = outcome.name,
test.df = test.df)
stopCluster(cl)
return(results)
}
test_aic <- get_stepwise_results(sample.list,column.names,y.name,test.df)
test_aic
#univariate
get_univarate_results <- function(sample.list, model.vars,outcome.name,test.df){
#Fits in parallel univariate p-value selection to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(model, test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
#helper to speed up
get_univariate_vars <- function(sample.df, model.vars,outcome.name,test.df){
fit.univarate <- function(df,model.vars,outcome.name,test.df){
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name,colnames(df))
#get x and y dataframes
df.x <- df[,-y.idx]; df.y <- as.factor(df[,y.idx])
#fit lm
train.ctrl <- trainControl("cv", 5,summaryFunction = twoClassSummary,
classProbs = T, allowParallel = T,
savePredictions = T)
fit.glm <- train(x = df.x , y = df.y ,
method = "glm",family=binomial(),
trControl = train.ctrl,
metric = 'ROC', trace=F)
#get vars
coef <- tidy(fit.glm$finalModel)
coef <- coef[-1,]
top.vars <- coef$term[coef$p.value < 0.05]
#score variable with 1 if it is in the model and 0 o.w
in.model <- as.numeric(model.vars %in% top.vars)
roc.val <- fit.glm$results$ROC
spec.sens <- spec_for_sens(fit.glm,test.df)
return(c(in.model,"univariate.pval",n, roc.val,spec.sens))
}
#fit row and get vars chosen
out.row <- as.data.frame(t(fit.univarate(sample.df,model.vars,outcome.name,test.df)))
model.vars <- c(model.vars, "method", "N", "ROC", "spec_for_sens")
names(out.row) <- model.vars
return(out.row)
}
#fit in parallel and get the results
cl <- makeCluster(detectCores())
clusterEvalQ(cl, {library(caret)
library(broom)})
results <- parLapply(cl, sample.list, get_univariate_vars,
model.vars = model.vars,outcome.name=outcome.name,
test.df =  test.df)
stopCluster(cl)
return(results)
}
test_univar <- get_univarate_results(sample.list,column.names,y.name,test.df)
test_univar
#lasso
get_lasso_results <- function(sample.list, model.vars,outcome.name){
#Fits in parallel LASSO regressiom for variable selectio to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(model, test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
#helper to speed up
get_lasso_vars <- function(sample.df, model.vars,outcome.name,test.df){
fit.lasso <- function(df, model.vars,outcome.name,test.df){
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name,colnames(df))
#get x and y dataframes
df.x <- model.matrix(formula(paste(outcome.name, "~", ".")), data = df); df.y <- as.factor(df[,y.idx])
#fit LASSO
train.ctrl <- trainControl("cv", 5,summaryFunction = twoClassSummary,
classProbs = T, allowParallel = T,
savePredictions = T)
fit.glm <- train(x = df.x, y = df.y ,
method = 'glmnet', trControl = train.ctrl,
metric = 'ROC', trace=F,
tuneGrid = expand.grid(alpha = 1,
lambda = seq(0.001,0.1,by = 0.001)),
family = "binomial")
#get vars
final.model <- coef(fit.glm$finalModel,fit.glm$bestTune$lambda)
top.vars <- rownames(final.model)[final.model[,1]!= 0]
#score variable with 1 if it is in the model and 0 o.w
roc.val <- max(fit.glm$results$ROC)
in.model <- as.numeric(model.vars %in% top.vars)
spec.sens <- spec_for_sens(fit.glm,test.df)
return(c(in.model,"LASSO",n, roc.val, spec.sens))
}
#fit row and get vars chosen
out.row <- as.data.frame(t(fit.lasso(sample.df,model.vars,outcome.name,test.df)))
model.vars <- c(model.vars,  "method", "N", "ROC", "spec_for_sens")
names(out.row) <- model.vars
return(out.row)
}
#fit in parallel and get the results
cl <- makeCluster(detectCores())
clusterEvalQ(cl, library(caret))
results <- parLapply(cl, sample.list, get_lasso_vars,
model.vars = model.vars, outcome.name=outcome.name,
test.df = test.df)
stopCluster(cl)
return(results)
}
#lasso
get_lasso_results <- function(sample.list, model.vars,outcome.name,test.df){
#Fits in parallel LASSO regressiom for variable selectio to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(model, test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
#helper to speed up
get_lasso_vars <- function(sample.df, model.vars,outcome.name,test.df){
fit.lasso <- function(df, model.vars,outcome.name,test.df){
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name,colnames(df))
#get x and y dataframes
df.x <- model.matrix(formula(paste(outcome.name, "~", ".")), data = df); df.y <- as.factor(df[,y.idx])
#fit LASSO
train.ctrl <- trainControl("cv", 5,summaryFunction = twoClassSummary,
classProbs = T, allowParallel = T,
savePredictions = T)
fit.glm <- train(x = df.x, y = df.y ,
method = 'glmnet', trControl = train.ctrl,
metric = 'ROC', trace=F,
tuneGrid = expand.grid(alpha = 1,
lambda = seq(0.001,0.1,by = 0.001)),
family = "binomial")
#get vars
final.model <- coef(fit.glm$finalModel,fit.glm$bestTune$lambda)
top.vars <- rownames(final.model)[final.model[,1]!= 0]
#score variable with 1 if it is in the model and 0 o.w
roc.val <- max(fit.glm$results$ROC)
in.model <- as.numeric(model.vars %in% top.vars)
spec.sens <- spec_for_sens(fit.glm,test.df)
return(c(in.model,"LASSO",n, roc.val, spec.sens))
}
#fit row and get vars chosen
out.row <- as.data.frame(t(fit.lasso(sample.df,model.vars,outcome.name,test.df)))
model.vars <- c(model.vars,  "method", "N", "ROC", "spec_for_sens")
names(out.row) <- model.vars
return(out.row)
}
#fit in parallel and get the results
cl <- makeCluster(detectCores())
clusterEvalQ(cl, library(caret))
results <- parLapply(cl, sample.list, get_lasso_vars,
model.vars = model.vars, outcome.name=outcome.name,
test.df = test.df)
stopCluster(cl)
return(results)
}
test_lasso <- get_lasso_results(sample.list,column.names,y.name,test.df)
#get n and variable names
n <- nrow(df); df <- na.omit(df); y.idx <- grep(outcome.name,colnames(df))
#get x and y dataframes
df.x <- model.matrix(formula(paste(outcome.name, "~", ".")), data = df); df.y <- as.factor(df[,y.idx])
#fit LASSO
train.ctrl <- trainControl("cv", 5,summaryFunction = twoClassSummary,
classProbs = T, allowParallel = T,
savePredictions = T)
fit.glm <- train(x = df.x, y = df.y ,
method = 'glmnet', trControl = train.ctrl,
metric = 'ROC', trace=F,
tuneGrid = expand.grid(alpha = 1,
lambda = seq(0.001,0.1,by = 0.001)),
family = "binomial")
#get vars
final.model <- coef(fit.glm$finalModel,fit.glm$bestTune$lambda)
top.vars <- rownames(final.model)[final.model[,1]!= 0]
#score variable with 1 if it is in the model and 0 o.w
roc.val <- max(fit.glm$results$ROC)
in.model <- as.numeric(model.vars %in% top.vars)
spec.sens <- spec_for_sens(fit.glm,test.df)
r1 <- pROC::roc(test.df$final_outcome_death, predict(fit.glm, test.df, 'prob')$X1
r1 <- pROC::roc(test.df$final_outcome_death, predict(fit.glm, test.df, 'prob')$X1)
roc(test.df$final_outcome_death,predict(fit.glm$finalModel,test.df))
roc(test.df$final_outcome_death,predict(fit.glm$bestTune,test.df))
fitted.values(fit.glm)
#Fits in parallel LASSO regressiom for variable selectio to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(fitted.values(model), test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
spec_for_sens(fit.glm,test.df)
#Fits in parallel LASSO regressiom for variable selectio to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(as.vector(fitted.values(model)), test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
spec_for_sens(fit.glm,test.df)
as.vector(fitted.values(fit.glm))
as.vector(as.factor(fitted.values(fit.glm)))
as.vector(as.numeric(as.factor(fitted.values(fit.glm))))
#Fits in parallel LASSO regressiom for variable selectio to a list of dataframes
#param: sample.list: list of dataframes containing sample data
#param: model.vars: the variable in dataframe
#param: outcome.name: string name of outcome
spec_for_sens <- function(model,test.df){
#compute roc
r1 <- pROC::roc(test.df$final_outcome_death, predict(as.vector(as.numeric(as.factor(fitted.values(model)))), test.df, 'prob')$X1) #computes ROC curve from model applied to test set
#spec
ss1 <- data.frame(r1$sensitivities, r1$specificities); names(ss1) <- c('Sens', "Spec")
#sens
spec1 <- dplyr::filter(ss1, abs(Sens - 0.8) == min(abs(Sens - 0.8)))$Spec
#if more than 1 get mean
if(length(spec1) > 1){
spec1 <- mean(spec1,na.rm=T)
}
return(spec1)
}
spec_for_sens(fit.glm,test.df)
as.vector(as.numeric(as.factor(fitted.values(fit.glm))))
predict(as.numeric(test.df$final_outcome_death), as.vector(as.numeric(as.factor(fitted.values(fit.glm))))
)
roc.glmnet(fit.glm,newx=test.df %>% select(-final_outcome_death),newy=test.df$final_outcome_death)
colnames(test.df)
predict(fit.glm,newx=test.df[,-19])
r1 <- pROC::roc(test.df$final_outcome_death, pred, 'prob')$X1) #computes ROC curve from model applied to test set
r1 <- pROC::roc(test.df$final_outcome_death, pred, 'prob')$X1 #computes ROC curve from model applied to test set
#compute roc
pred <- predict(fit.glm,newx=test.df[,-19])
r1 <- pROC::roc(test.df$final_outcome_death, pred, 'prob')$X1 #computes ROC curve from model applied to test set
roc(test.df$final_outcome_death,pred)
roc(test.df$final_outcome_death,pred, "prob")
pred
test.df$final_outcome_death
roc(as.factor(test.df$final_outcome_death),pred, "prob")
as.factor(test.df$final_outcome_death)
roc(as.factor(test.df$final_outcome_death),as.factor(pred))
type(pred)
typeof(pred)
pred
as.factor(pred()
)
as.factor(pred)
typeof(as.factor(pred))
typeof(as.numeric(pred))
(as.numeric(pred))
r1 <- pROC::roc(test.df$final_outcome_death, as.numeric(pred), 'prob')$X1 #computes ROC curve from model applied to test set
r1 <- pROC::roc(response = test.df$final_outcome_death,predictor = as.numeric(pred), 'prob')$X1 #computes ROC curve from model applied to test set
roc(response = as.numeric(test.df$final_outcome_death),predictor = as.numeric(pred), 'prob')$X1
roc(test.df$final_outcome_death, pred)
roc(test.df$final_outcome_death, pred, "pred")
roc(test.df$final_outcome_death, pred, "prob")
roc(test.df$final_outcome_death, predictor = pred, "prob")
is.ordered(test.df$final_outcome_death)
is.ordered(pred)
typeof(pred)
typeof(test.df$final_outcome_death)
typeof(as.factor(test.df$final_outcome_death))
typeof(as.factor(test.df$final_outcome_death));typeof(pred)
roc(as.factor(test.df$final_outcome_death), predictor = pred, "prob")
roc(as.factor(test.df$final_outcome_death), pred )
is.numeric(pred)
is.numeric(as.factor(test.df$final_outcome_death))
is.numeric(as.numeric(as.factor(test.df$final_outcome_death)))
roc(as.numeric(as.factor(test.df$final_outcome_death)), as.numeric(pred ))
length(pred)
length(test.df$final_outcome_death)
